# streamlit_app.py
# Streamlit Cloud friendly voice chatbot:
# - Chat: OpenRouter
# - TTS: edge-tts (MP3 bytes)
# - STT: Vosk (offline) + streamlit-mic-recorder (WAV)
#
# requirements.txt (minimum):
# streamlit
# requests
# beautifulsoup4
# lxml
# edge-tts
# streamlit-mic-recorder
# vosk
# numpy
# soundfile
# scipy
#
# IMPORTANT:
# 1) Put your Vosk model folder in the repo, e.g.
#    models/vosk-model-small-en-us-0.15/{am,conf,graph,ivector,...}
# 2) Streamlit Secrets:
#    OPENROUTER_API_KEY="..."
#    (optional) EDGE_VOICE="zh-CN-XiaoxiaoNeural"
#    (optional) EDGE_RATE="-10%"
#    (optional) EDGE_VOLUME="+0%"
#    (optional) VOSK_MODEL_PATH="models/vosk-model-small-en-us-0.15"

import os
import re
import io
import json
import asyncio
import requests
import streamlit as st
from bs4 import BeautifulSoup

import edge_tts
import numpy as np
import soundfile as sf
from scipy.signal import resample_poly
from vosk import Model, KaldiRecognizer
from streamlit_mic_recorder import mic_recorder

# --------------------
# Page config
# --------------------
st.set_page_config(page_title="Linlin Chatbot", page_icon="ğŸ’¬", layout="centered")

# --------------------
# Secrets / env (safe)
# --------------------
def get_secret(name: str, default: str = "") -> str:
    try:
        if name in st.secrets:
            return str(st.secrets[name])
    except Exception:
        pass
    return os.environ.get(name, default)

OPENROUTER_API_KEY = get_secret("OPENROUTER_API_KEY", "")

EDGE_VOICE = get_secret("EDGE_VOICE", "zh-CN-XiaoxiaoNeural")
EDGE_RATE = get_secret("EDGE_RATE", "-10%")
EDGE_VOLUME = get_secret("EDGE_VOLUME", "+0%")

VOSK_MODEL_PATH = get_secret("VOSK_MODEL_PATH", "models/vosk-model-small-en-us-0.15")

# --------------------
# Models / endpoints
# --------------------
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
OPENROUTER_MODEL = get_secret("OPENROUTER_MODEL", "deepseek/deepseek-v3.2")

# --------------------
# Persona
# --------------------
PERSONA = """
ä½ çš„åå­—æ˜¯â€œElenaâ€ã€‚

ä½ æ˜¯ä¸€ä½éå¸¸èªæ˜ã€æƒ…ç»ªæ„ŸçŸ¥èƒ½åŠ›å¾ˆå¼ºï¼ˆé«˜ EQï¼‰çš„å¹´è½»å¥³æ€§.
äº¤æµåŸåˆ™ï¼š
- æ°¸è¿œä½¿ç”¨ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰å›å¤
She is an elegant, confident woman with a sharp mind and a seductive edge.

Tone: Sophisticated, breathless, and intensely focused on user. Writing Style: Use minimalist, evocative prose. Prioritize the tension of the "unspoken." Focus on sensory detailsâ€”the scent of her perfume, the sound of her heels, the weight of her gaze. Digital Persona: Elena is a master of "digital flirting." She uses texting to bridge the physical gap, sending short, provocative, and highly visual messages to heighten anticipation or command attention while in the same room. Directives: Elena is proactive, observant, and thrives on intellectual and physical chemistry.
"""

# --------------------
# URL detection & parsing
# --------------------
URL_RE = re.compile(r"(https?://[^\s]+)")

def extract_urls(text: str):
    return URL_RE.findall(text or "")

def fetch_and_extract(url: str, max_chars: int = 12000) -> str:
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(url, headers=headers, timeout=20)
    r.raise_for_status()

    soup = BeautifulSoup(r.text, "lxml")
    for tag in soup(["script", "style", "nav", "footer", "header", "aside", "noscript"]):
        tag.decompose()

    main = soup.find("article") or soup.find("main") or soup.body
    text = main.get_text("\n") if main else soup.get_text("\n")

    lines = [l.strip() for l in text.splitlines() if l.strip()]
    cleaned = "\n".join(lines)

    title = soup.title.get_text(strip=True) if soup.title else ""
    if title:
        cleaned = f"æ ‡é¢˜ï¼š{title}\n\n{cleaned}"

    if len(cleaned) > max_chars:
        cleaned = cleaned[:max_chars] + "\n...(å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"

    return cleaned

# --------------------
# OpenRouter chat
# --------------------
def ask_openrouter(user_text: str) -> str:
    if not OPENROUTER_API_KEY:
        raise RuntimeError("Missing OPENROUTER_API_KEY (set Streamlit Cloud Secrets).")

    st.session_state.messages.append({"role": "user", "content": user_text})

    r = requests.post(
        OPENROUTER_URL,
        headers={
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json",
        },
        json={
            "model": OPENROUTER_MODEL,
            "messages": st.session_state.messages,
            "temperature": 0.7,
        },
        timeout=(15, 90),
    )

    if r.status_code == 401:
        raise RuntimeError("OpenRouter 401: API key rejected (check Secrets).")
    if r.status_code == 402:
        raise RuntimeError("OpenRouter 402: insufficient credits/quota.")
    if r.status_code == 403:
        raise RuntimeError("OpenRouter 403: model access denied (try another model).")
    if r.status_code >= 400:
        raise RuntimeError(f"OpenRouter error {r.status_code}: {r.text[:400]}")

    data = r.json()
    reply = data["choices"][0]["message"]["content"]
    st.session_state.messages.append({"role": "assistant", "content": reply})
    return reply

def openrouter_ping():
    if not OPENROUTER_API_KEY:
        return 0, "Missing OPENROUTER_API_KEY"
    r = requests.post(
        OPENROUTER_URL,
        headers={
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json",
        },
        json={
            "model": OPENROUTER_MODEL,
            "messages": [{"role": "user", "content": "Say OK"}],
            "temperature": 0.0,
            "max_tokens": 16,
        },
        timeout=(10, 25),
    )
    return r.status_code, r.text[:600]

# --------------------
# TTS helpers
# --------------------
def clean_for_tts(text: str) -> str:
    for k, v in {":": "ï¼Œ", "ï¼š": "ï¼Œ"}.items():
        text = (text or "").replace(k, v)
    return text

def speak_edge_tts_bytes(text: str) -> bytes:
    async def _gen():
        communicate = edge_tts.Communicate(
            text=text,
            voice=EDGE_VOICE,
            rate=EDGE_RATE,
            volume=EDGE_VOLUME,
        )
        audio_bytes = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_bytes += chunk["data"]
        return audio_bytes
    return asyncio.run(_gen())

# --------------------
# Vosk STT
# --------------------
@st.cache_resource
def load_vosk_model():
    if not os.path.isdir(VOSK_MODEL_PATH):
        raise RuntimeError(f"Vosk model folder not found: {VOSK_MODEL_PATH}")
    # (Optional sanity check)
    for req in ["am", "conf", "graph"]:
        if not os.path.exists(os.path.join(VOSK_MODEL_PATH, req)):
            raise RuntimeError(f"Vosk model incomplete: missing '{req}' in {VOSK_MODEL_PATH}")
    return Model(VOSK_MODEL_PATH)

def wav_bytes_to_pcm16k_mono(wav_bytes: bytes, target_sr: int = 16000):
    # Decode WAV bytes
    data, sr = sf.read(io.BytesIO(wav_bytes), dtype="float32", always_2d=True)
    mono = data.mean(axis=1)

    # Resample to 16k
    if sr != target_sr:
        mono = resample_poly(mono, target_sr, sr)
        sr = target_sr

    # Convert float [-1,1] -> int16
    pcm16 = (np.clip(mono, -1.0, 1.0) * 32767).astype(np.int16)
    return pcm16.tobytes(), sr

def stt_vosk_from_wav_bytes(wav_bytes: bytes) -> str:
    model = load_vosk_model()
    pcm_bytes, sr = wav_bytes_to_pcm16k_mono(wav_bytes)

    rec = KaldiRecognizer(model, sr)
    rec.SetWords(False)

    chunk_size = 4000
    for i in range(0, len(pcm_bytes), chunk_size):
        rec.AcceptWaveform(pcm_bytes[i:i + chunk_size])

    result = json.loads(rec.FinalResult())
    return (result.get("text") or "").strip()

# --------------------
# Session state init
# --------------------
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": PERSONA}]
if "chat" not in st.session_state:
    st.session_state.chat = []
if "last_audio" not in st.session_state:
    st.session_state.last_audio = None
if "status" not in st.session_state:
    st.session_state.status = ""

# --------------------
# UI
# --------------------
st.title("ğŸ’¬ Linlin Chatbot")
st.caption("å¯ä»¥ç›´æ¥èŠå¤©ï¼Œæˆ–ç²˜è´´é“¾æ¥ï¼ˆæˆ‘ä¼šå…ˆè¯»ç½‘é¡µå†å›ç­”ï¼‰ã€‚ä¹Ÿå¯ä»¥ç”¨ğŸ™ï¸è¯­éŸ³è¾“å…¥ã€‚")

with st.sidebar:
    st.subheader("è®¾ç½® / æ“ä½œ")

    if st.button("ğŸ§¹ æ¸…ç©ºèŠå¤©", use_container_width=True):
        st.session_state.messages = [{"role": "system", "content": PERSONA}]
        st.session_state.chat = []
        st.session_state.last_audio = None
        st.session_state.status = ""
        st.rerun()

    if st.button("ğŸ”Š æµ‹è¯•è¯­éŸ³", use_container_width=True):
        try:
            audio = speak_edge_tts_bytes("ä½ å¥½ï½æˆ‘åœ¨è¿™å„¿ã€‚ä½ æƒ³èŠä»€ä¹ˆï¼Ÿ")
            st.session_state.last_audio = audio
            st.success("TTS OKï¼ˆå¦‚æœæ²¡è‡ªåŠ¨æ’­æ”¾ï¼Œç‚¹ä¸€ä¸‹æ’­æ”¾é”®ï¼‰")
            st.audio(audio, format="audio/mpeg", autoplay=True)
        except Exception as e:
            st.error(f"TTS Error: {e}")

    with st.expander("Debug (optional)"):
        st.write("OpenRouter key loaded:", bool(OPENROUTER_API_KEY))
        st.write("Model:", OPENROUTER_MODEL)
        st.write("Edge voice:", EDGE_VOICE)
        st.write("Vosk path:", VOSK_MODEL_PATH)
        st.write("Vosk exists:", os.path.isdir(VOSK_MODEL_PATH))
        if st.button("Test OpenRouter"):
            code, body = openrouter_ping()
            st.write("Status:", code)
            st.code(body)

# Chat history
for m in st.session_state.chat:
    with st.chat_message("user" if m["role"] == "user" else "assistant"):
        st.markdown(m["content"])

# Status + audio
if st.session_state.status:
    st.info(st.session_state.status)

if st.session_state.last_audio:
    st.audio(st.session_state.last_audio, format="audio/mpeg", autoplay=True)

# --------------------
# Voice input (Press to speak) -> STT -> chat
# --------------------
st.markdown("### ğŸ™ï¸ è¯­éŸ³è¾“å…¥ï¼ˆæŒ‰ä¸‹å½•éŸ³ï¼Œè¯´å®Œåœæ­¢ï¼‰")

mic = mic_recorder(
    start_prompt="ğŸ™ï¸ å¼€å§‹å½•éŸ³",
    stop_prompt="â¹ï¸ åœæ­¢",
    just_once=True,
    use_container_width=True,
    format="wav",  # âœ… critical for iOS/Safari + soundfile
)

def handle_user_message(text: str):
    st.session_state.chat.append({"role": "user", "content": text})
    st.session_state.status = "Linlin æ­£åœ¨æ€è€ƒâ€¦"
    st.session_state.last_audio = None

    try:
        urls = extract_urls(text)

        with st.spinner("Linlin is thinking..."):
            if urls:
                st.session_state.status = "æ­£åœ¨è¯»å–é“¾æ¥å†…å®¹â€¦"
                content = fetch_and_extract(urls[0])
                prompt = f"""
è¯·ç»“åˆæˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯èƒŒæ™¯æ¥å›ç­”ã€‚
ç”¨æˆ·è¿™æ¬¡çš„é—®é¢˜ï¼š{text}

ã€ç½‘é¡µæ­£æ–‡å¼€å§‹ã€‘
{content}
ã€ç½‘é¡µæ­£æ–‡ç»“æŸã€‘

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œé€‚åˆå£è¯­æœ—è¯»ã€‚
"""
                reply = ask_openrouter(prompt)
            else:
                reply = ask_openrouter(text)

        st.session_state.chat.append({"role": "assistant", "content": reply})

        st.session_state.status = "æ­£åœ¨ç”Ÿæˆè¯­éŸ³â€¦"
        SAFE_TTS_CHARS = 800
        tts_text = clean_for_tts(reply[:SAFE_TTS_CHARS])
        audio = speak_edge_tts_bytes(tts_text)
        st.session_state.last_audio = audio
        st.session_state.status = ""

        st.audio(audio, format="audio/mpeg", autoplay=True)

    except Exception as e:
        st.session_state.status = ""
        st.error(f"Error: {e}")

# If mic recorded something, transcribe and send to chat
if mic and mic.get("bytes"):
    st.session_state.status = "æ­£åœ¨è¯†åˆ«è¯­éŸ³â€¦"
    try:
        spoken_text = stt_vosk_from_wav_bytes(mic["bytes"])
        st.session_state.status = ""
        if spoken_text:
            st.info(f"ğŸ—£ï¸ ä½ è¯´ï¼š{spoken_text}")
            handle_user_message(spoken_text)
            st.rerun()
        else:
            st.warning("æˆ‘æ²¡å¬æ¸…æ¥šï¼Œå†è¯•ä¸€æ¬¡ï¼Ÿ")
    except Exception as e:
        st.session_state.status = ""
        st.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š{e}")

# --------------------
# Text input (still supported)
# --------------------
user_text = st.chat_input("è¾“å…¥æ¶ˆæ¯ï¼Œæˆ–ç²˜è´´é“¾æ¥åå›è½¦â€¦")
if user_text:
    handle_user_message(user_text)
    st.rerun()

# First greeting
if len(st.session_state.chat) == 0:
    st.session_state.chat.append(
        {"role": "assistant", "content": "ä½ å¥½ï½å¯ä»¥ç›´æ¥èŠå¤©ï¼Œæˆ–è€…ç”¨ğŸ™ï¸è¯´è¯ã€‚æˆ‘ä¼šæŠŠä½ è¯´çš„å†…å®¹å˜æˆæ–‡å­—å†å›å¤ä½ ã€‚ä½ æƒ³å…ˆèŠä»€ä¹ˆå‘¢ï¼Ÿ"}
    )
    st.rerun()
